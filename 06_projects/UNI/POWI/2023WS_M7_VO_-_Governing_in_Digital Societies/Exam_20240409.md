# Exam_20240409
**Author:** Utku B. Demir | 0848242
1.    
2.     
3.      (25)
4.     A

5.     

>[!question]
>  What kind of historical and current issue(s) does this meme refer to, and what would be some approaches to solving the problems associated with it? Please refer to concrete examples given by the speaker(s). According to the speaker(s), what are some current trends or ideas to solve the issue(s) described in the meme? (20)

![Simon Grund @simongrund@sciences.social on X: "This meme ...](file:////Users/ubd/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_image001.jpg)

This issue has been addressed at Katja Mayer's session. Mayer's investigation into data practices reveals a multi-faceted view of openness aiming to understand how openness is evolved in real-world research practices. Open Science practices are initially appeals to inclusivity and emphasises a common human knowledge accessible by everyone. And the digital realm was initially the biggest hope humanity has ever discovered in this regard. Digital platforms and the digital expansion of knowledge have been presented as the bastions of a connected world with equal access to any kind of intellectual production we might deploy. However, as the digital agora became an attention exploitation machine, as the social media became a market to exploit poeple's time to miliseconds in order to expand capital accumulation, our hopes for open science has been conquered by the academic publishing industry, leading not just to blocking walls for the readers but also economic disparity for the actual academics. High subscription fees and article processing charges (APCs) are identified as significant hurdles, especially for researchers from developing countries, perpetuating a divide in who can access and contribute to scholarly communication​​.
Mayer delves into various dimensions of Open Science, including open data practices, open access publishing, and the broader implications for research governance and responsible innovation. Dr. Mayer advances the discourse on how open practices can contribute to more equitable and inclusive research landscapes. The discussion also follows both the potential benefits of Open Science, such as enhanced visibility for marginalised groups and broader accessibility, and the challenges it poses, including cost barriers, institutional dependencies, and persistent biases. Mayer empohasies for a nuanced understanding of Open Science that addresses these dualities​​.
As a personal note while finding the open science struggle extremely valuable, I suggest and support piracy. Open Science shouldn't be about a work around around the proprietary publishing companies. We as the people of the digital platform also have a strategy and hopefully also strength to bend the rising walls to our will.

## Summary of Dr. Philip Mirowski's Article on Open Science:

Dr. Philip Mirowski's critique in "The future(s) of open science" focuses on the alignment of Open Science with platform capitalism, raising concerns about how the movement, while advocating for openness, may inadvertently serve to re-engineer scientific practices in ways that prioritize market imperatives over genuine democratization and inclusivity of scientific knowledge​​.

Mirowski highlights several issues purportedly addressed by Open Science, such as public distrust in science and the democracy deficit in scientific practices. He argues that the movement's approach, especially its emphasis on radically collaborative science facilitated by digital platforms, might not effectively remedy these issues but rather align science more closely with neoliberal market logic​​.

## Convergence of Themes:

Both Dr. Mayer's lecture and Dr. Mirowski's article critically assess the complex landscape of Open Science, drawing attention to the underlying economic, social, and ethical dimensions. They underscore the importance of critically evaluating the impacts of open practices, advocating for approaches that genuinely foster inclusivity, equity, and responsible governance in scientific research.

By weaving together insights from these discussions, it becomes clear that while Open Science holds transformative potential, realizing this potential necessitates vigilant attention to the unintended consequences and challenges that accompany the movement towards greater openness in the scientific domain.

>[!question]
> Thinking of the lecture by Keegan, describe some of the most pressing ethical governmental and regulatory challenges he addressed. What are some concrete steps that could be taken by the actors involved? Why, according to your own opinion, would these steps be promising (or not)? Be sure to apply arguments made by Keegan to your chosen example. (20)

Keegan is especially focusing the struggle for the data sovereignity to underline specific challenges in terms of data protectin and management especially in the vulnerable and marginalised groups. Indigenous communities are especially important examples in this sense because they often have enormous collections of "tangible and intangible cultural material, knowledge, and data, held in archives, museums, libraries, repositories, and other online databases" (from his presentation). As the historical examples of how cultural heritage of the indigenous communities were exploited, protecting the digital heritage of these communities is of grave importance on the way to an ethical global data ownership structure. But the vulnerable data aspects of the indigenous communities go way beyond the cultural heritage, there are lots of personal data, data about community history, lineage, personal remarks, sources which should be intellectual property, metadata about basically every aspect of the community that are simply mixed in those databases.

The increasing use of AI in surveillance technologies by governments and corporations, raising significant privacy concerns and the potential for misuse for these comminties. There is also the potential challenges in this term of Ai systems possibly perpetuating or exacerbating existing social biases, leading to unfair outcomes for marginalized groups. Especially, when AI is included in the data process, there is the difficulty in tracing AI decisions back to human actors, complicating legal and ethical accountability, especially in critical areas like healthcare, criminal justice, and finance. With these considerations, the only way to prevent data from being potentially misused or used against the benefit of the community is to deploy an effective method for data sovereignity.

Maoris as an indigenous community realised the importance of their data and started protecting it as they protect valuable aspects in their culture. Accordingly to the cultural strategy for Maori people to protect their valuables there had to be a methodology to signify the importance of their data. This methodology should make the whole community even the digitally illiterate parts of the society aware about the importance of data sovereignity. In this pursuit, communities' data has been named as Taonga, so they adapted an already traditional defence strategy to protect a new valuable aspect of their society (Kukutai et al.). A specific concept which was already established has been used to emphasise the significance and vulnerability of a new valuable. Indeed, by defining data as "Taonga" (treasure), Māori communities emphasize the cultural and intrinsic value of data, extending traditional protections and values to digital information. This classification not only highlights the significance of data within Māori society but also demands a stewardship approach grounded in Māori ethical frameworks and worldviews. It's a reassertion of sovereignty over an intangible asset, aligning modern data practices with ancient principles of guardianship and responsibility. The concept of Taonga reinforces community awareness about the importance of data and ensures collective engagement in its governance. It fosters a communal approach to data management, where decisions regarding data are made in ways that benefit the collective well-being of Māori people, respecting their rights, traditions, and aspirations. This community-centric approach is a cornerstone of how Māori data should be collected, analyzed, and shared, ensuring that it serves the interests of Māori communities first and foremost.

While we are struggling with data sovereignty in general, it is a fresh breath of air to see there are unique approaches applying the collective human knowledge to this prominent and contemporary issue. However, the data management landscape has to be adapted much better to such kind of novel approaches that introduce variety into the system. Currently, we are struggling (at some fronts it is already emphasised that the data war has been lost for the people) to establish any kmind of data sovereignity while most of us become the instruments of their own defeat.

As the digital landscape evolves, the integration of indigenous knowledge systems and values offers a valuable perspective on data governance that emphasises ethics, community benefit, and cultural sensitivity. The challenge lies in reconciling these approaches with prevailing data practices that are often rooted in individualistic and commercial interests. Achieving Māori Data Sovereignty requires adjustments in legal, technological, and policy frameworks to accommodate and respect indigenous approaches to data governance. It represents a broader call for inclusivity and diversity in how we conceptualise and manage data in the digital age. While not without challenges, these novel approaches might lead us to building new ways to data sovereignity as well.

>[!question]
> Do you think a global agreement on responsible AI (artificial intelligence) governance is feasible? Why or why not? In your response, please refer to relevant literature and lecture(s), as well as your own opinion and arguments. If applicable, you can also give examples from (an) other lecture(s) or class(es) you have taken in your political science education to form an argument about global (AI) governance. (25)

This question might connect to a couple of sessions.  I think Eugenia Stamboliev's, Rene König's, Fiske's, and Ruttkamp's lectures are all touching this question to some extent. But, I would like to argument with my own words first. Of course there is a challenge because of the current inner structure of what we call AI. With the development of the neural networks, we went into the completely black box structure of AIs. With the whole deep learning approaches, unsupervised learning, generative approaches and now the star child of all these progresses, the LLMs made the understanding of the inner working of the AI more and more harder. On top of that, our currrent development regarding AI Models is simply "let's make it bigger". However, this is a technical challenge, and given we direct ourselves to the correct direction, nothing unsolveable even with our primitive understanding of them for the time being. However, there is one problem which we couldn't solve for any kind of technological development, we cannot solve capitalist production cycle. We simply cannot even mitigate the climate change without making it at least a little bit profitable for huge companies. THe same powerlessnes is also valid for the AI.

I can't recall lecturer's name, but I think one of the most important points in the whole LV was the topic of how to make the individual ethical considerations to macro ethical considerations. How to make huge tech companies to do as much ethical considerations as we do on a micro level (Stamboliev?). This the inherent question valid for AI or any kind of process for that matter. Because of the time pressure, I cannot follow anymore. Once we build a public organisation to force companies to ethical considerations (of course with public founding and hiring experts), the measures Singh mentions will be easy to implement. 

>[!question]
> According to Wadmann, how might increased digitalization alter the relationship between citizens and government authorities? Give concrete examples from the lecture and/or the accompanying text, as well as your own experiences. (20)

Wadmann focueses on Denmark's transformation into being the forefront of integrating digital solutions into its welfare state, aiming to create an efficient, accessible, and user-friendly public service system. The digital government approaches in Denmark are ranked to be the one of the best in e-government surveys. This transformation involves not only digitilasing existing services but also rethinking how services are designed and delivered to ensure they meet the needs of a digitally connected society (Wadmann's presentation mainly). While Denmark's digital welfare state presents significant opportunities for streamlining operations and as Pors and Pallesen notes taking the bureaucracy out of the Weber's definition of alienating kafkaesque structure by enhancing service speeed, eliminating unnecessary steps, reducing the number of physical documents, physical attendences and in general the long ques, it also poses challenges, particularly concerning social inclusion. As services move online, there's a risk of widening the digital divide, leaving behind those without access to digital technologies or the skills to use them effectively.

To combat the potential exclusionary effects of digitilasation, Denmark has implemented several digital inclusion strategies. However, one thing I would like to argue is that these challenges are happening in lots of other sectors as well. We are facing an issue f accessibility of the older generations, vulnerable and marginalised communities to the newly developed novel digital systems on a vast scale. Denmark's governmental approaches are just a good collection of good practies. These include initiatives to increase digital literacy and accessibility, ensuring that all citizens have the skills and means to access digital services. Programs targeting elderly citizens, people with disabilities, and those in remote areas are of particular focus, reflecting a comprehensive approach to bridging the digital divide. While the capacity building is a huge part of the any mitigation appraoch in this regard, Denmark's journey also underlines how much we are still depending on building consultation systems for each of the novel digitalisation related transformations. This also constitues one of the good practices in Denmark. 

Despite these efforts, concerns remain about the digital divide and its implications for social equity. The shift to digital governance requires continuous attention to the accessibility and usability of online services, ensuring they cater to the diverse needs of the population. It's crucial that digital welfare approaches do not create further marginalisation, combating this issue becomes the further problematic. We could also link the AMS' AMAS algorithm in Austria, a system geared towards increasing effectiveness to help people in need but is constantly creating novel marginalisations for already marginalised people. 

The Danish model seeks to mitigate potential challenges faced by vulnerable populations through user-centered design, widespread digital literacy campaigns, and providing alternative access points to digital services. These efforts are aimed at ensuring that the digital transformation of the welfare 
state increases the seamless brueaucracy for the benefit of everyone.  As Denmark continues to evolve its digital welfare state,the experiences and lessons learned from Denmark's approach offer valuable insights for other countries navigating the transition to digital governance. 

>[!question]
> Think about the materiality of data (storage) centers and where they are located. According to the speaker(s), there are contradictions inherent in how the public imagines (big) data and the material places where data and knowledge are stored? Discuss this contradiction referring to relevant literature or lectures. Why is this relevant for governance and the shaping of public opinion? (15)

# References
1. Kukutai, T., Campbell-Kamariera, K., Mead, A., Mikaere, K., Moses, C., Whitehead, J. & Cormack, D. (2023). Māori data governance model. Te Kāhui Raraunga.
2. [[2023WS_M7_VO_-_Governing_in_Digital Societies]]