---
category: literature_note
aliases: 
  - Deconstructing Transformers
  - maas2023
tags:
  - literature_note
  - zotero
  - ✅, ❗️
citekey: maas2023
---

|       Created       |    Last Modified    |          Exists Since           |
| :-----------------: | :-----------------: | :-----------------------------: |
| `= this.file.ctime` | `= this.file.mtime` | `= date(now) - this.file.ctime` |
>[!info] Metadata
> **FirstAuthor**:: Maas, Wouter  
~    
> **Title**:: Deconstructing Transformers  
> **Year**:: 2023   
> **Citekey**:: maas2023  
> **itemType**:: journalArticle  
> **Journal**:: **    

> [!link]-
> zotero_link:: [Maas_Deconstructing Transformers.pdf](zotero://select/library/items/4L4ULCUY)

> [!cite]-
> citekey:: maas2023

> [!abstract]-
> abstract:: 

> [!keywords]-
> keywords:: ✅, ❗️

> [!authors]-
> authors:: Wouter Maas

> [!related]-

```dataview
TABLE created, updated as modified, tags, type
FROM ""
WHERE related != null
AND contains(related, "maas2023")
```

> [!hypothesis]-
> hypothesis:: 

> [!methodology]- 
> methodology:: 

> [!result]- Result(s) 
> results::

> [!summary]- Summary of Key Points
> summary:: 

# Notes

| <mark class="hltr-grey">Highlight Color</mark> | Meaning                       |
| ---------------------------------------------- | ----------------------------- |
| <mark class="hltr-yellow">Yellow</mark>        | Interesting Point             |
| <mark class="hltr-orange">Orange</mark>        | Important Point By Author     |
| <mark class="hltr-red">Red</mark>              | Disagree with Author          |
| <mark class="hltr-blue">Blue</mark>            | Support the Author            |
| <mark class="hltr-magenta">Magenta</mark>      | Important To Me               |
| <mark class="hltr-purple">Purple</mark>        | Literary Note To Lookup Later |
| <mark class="hltr-green">Green</mark>          | Example                       |
| <mark class="hltr-grey">Grey</mark>            | New term, - definition        |

- <mark class="hltr-yellow">"elf-supervised learning, in the context of LLMs, is an approach where the LLM creates its own prediction challenges from text to learn an enormous amount of knowledge about language and the world (Manning, 2022, pp. 129-30). The LLM is exposed to an extremely large quantity of text, typically billions of words. The learning method involves identifying the next word in the text given the previous words or filling in a masked word or phrase in a text. By repeating such prediction tasks billions of times and learning from its mistakes, the model accumulates general knowledge of language and the world, which can then be used for tasks such as question answering or text classification. This approach has proven to be very successful in NLP, as it does not require manual annotations or human supervision, making it a cost-effective method for training LLMs.”</mark> [Page 5](zotero://open-pdf/library/items/4L4ULCUY?page=5&annotation=NZ8GKX2C) 
	- <mark class="hltr-yellow">"This process is performed multiple times with multiple ‘heads’ in parallel. The concept of ‘multi-head’ attention allows the model to focus on different positions and capture various aspects of the input information simultaneously. Each head computes a separate attention score, query, key, and value, enabling the model to capture different types of relationships in the data. For instance, one head may focus on the grammatical structure of a sentence, while another may pay more attention to the semantic context. The results from all heads are then concatenated and linearly transformed to form the final output.”</mark> [Page 5](zotero://open-pdf/library/items/4L4ULCUY?page=5&annotation=5FNS25WW) 
	- <mark class="hltr-yellow">"Although the image sketched in the previous sections is one of wonder and achievement, prominent authors in the field of language philosophy, such as Noam Chomsky, have spoken out against the idea that LLMs contain ‘knowledge’ in the way that humans do (Chomsky et al., 2023). The central idea that these philosophers are after is that LLMs do not have the same kind of special relationship with propositions that humans do. Shanahan (2023, p. 3, p. 5) argues in line with Chomsky et al. (2023) that due to the fact that “the basic function of a large language model is to generate statistically likely continuations of word sequences”, at the most fundamental level an LLM “doesn’t ‘really’ know anything, […] because all it does is sequence prediction”. Shanahan (2023) therefore concludes:  The real issue here is that, whatever emergent properties it has, the LLM itself has no access to any external reality against which its words might be measured, nor the means to apply any other external criteria of truth, such as agreement with other language-users. […] The point here does not concern any specific belief. It concerns the prerequisites for ascribing any beliefs at all to a system. Nothing can count as a belief about the world we share — in the largest sense of the term — unless it is against the backdrop of the ability to update beliefs appropriately in the light of evidence from that world, an essential aspect of the capacity to distinguish truth from falsehood. (p. 6)”</mark> [Page 7](zotero://open-pdf/library/items/4L4ULCUY?page=7&annotation=9IB8HDS3) 
	- <mark class="hltr-orange">"The investigation of these undermining effects, as well as the attempt to encounter new, unexpected, and perhaps yet unimagined meanings through this investigation, is what Derrida early on referred to as deconstruction (Ten Kate et al., 2007, p. 120).”</mark> [Page 8](zotero://open-pdf/library/items/4L4ULCUY?page=8&annotation=4ES6MWCP) 
	- <mark class="hltr-orange">"Thus, Derrida deduces that language is characterized by a lack or absence: it can never completely capture reality to present it as present, but its structure is fundamentally dictated by the very absence of that reality. Consequently, the signs making up language are to be interpreted as supplements, but in a much deeper sense of the term supplement: they serve as an external addition, supplementing for an internal void. Meaning only emerges as an added component. However, this addition, the supplement, simultaneously obscures the meaning it just revealed. This playful elusiveness of meaning is probably best explained through Derrida’s principle of diff ́erance.”</mark> [Page 9](zotero://open-pdf/library/items/4L4ULCUY?page=9&annotation=DJ56CL4F) 
	- <mark class="hltr-yellow">"Finally, a detail that should not be overlooked is that diff ́erance and ‘diff ́erence’ sound exactly the same in French, the difference is thus only noticeable in writing and not in speech. This is a subtle way in which Derrida wants to undermine the earlier mentioned assumption of the primacy of speech within the Western philosophical tradition.”</mark> [Page 10](zotero://open-pdf/library/items/4L4ULCUY?page=10&annotation=KW7KCMXP) 
	- <mark class="hltr-orange">"For Derrida, the meaning of words is thus always context-dependent and solely defined in relation to other meanings.”</mark> [Page 10](zotero://open-pdf/library/items/4L4ULCUY?page=10&annotation=J9DMT26P) 
	- <mark class="hltr-orange">"This last point is important for Derrida, as it signifies that a sign itself does not poses any positive content. As such, “the sign has no component that belongs to itself only; it is merely a collection of the traces of every other sign running through it” (Cilliers, 2002, p. 44). This means that the traces constructing a sign, also cannot originate from some other self-sufficient signs with inherent meaning to impart. Rather, all signs are shaped within the interplay of differences, a dynamic process of combination and referencing that forbids the existence of isolated, standalone elements (Cilliers, 2002, p. 44).”</mark> [Page 10](zotero://open-pdf/library/items/4L4ULCUY?page=10&annotation=X9EUMRJ4) 
	- <mark class="hltr-orange">"Given the dispersed nature of these relationships, a singular weight doesn’t hold any conceptual content; instead, it obtains relevance through extensive interaction patterns.”</mark> [Page 12](zotero://open-pdf/library/items/4L4ULCUY?page=12&annotation=33EDMY3E) 
	- <mark class="hltr-orange">"Finally, Section 3.2.3 explores how LLMs ability to be jailbroken demonstrates how they escape a structural explanation by allowing their own deconstruction.”</mark> [Page 13](zotero://open-pdf/library/items/4L4ULCUY?page=13&annotation=B6Z2WVY7) 
	- <mark class="hltr-orange">"However, there are also some important differences. Transformer Networks do not inherently involve the same kind of recursive, feedback loops that characterize RNNs. They do not take the output of a node and return it as input to the same node. Instead, the self-attention mechanism allows every token to simultaneously consider every other token, in a kind of ‘global’ context. This gives transformers a form of ‘awareness’ of the entire sequence at once, which is different from the recursive, deferential nature of RNNs described by Cilliers. Arguably, this could be seen as bringing modern LLMs closer to Derrida’s original ideas regarding the trace, as the self-attention mechanism bakes in the haunting of other words in the representation of each word’s meaning within the LLM.”</mark> [Page 13](zotero://open-pdf/library/items/4L4ULCUY?page=13&annotation=7XW5TYQ5) 
	- <mark class="hltr-orange">"Arguably, LLMs enable their own deconstruction, which becomes evident in the free, fluid, and open-ended manner in which they generate natural language. Exemplary for this behavior is the possibility of ‘jailbreaking’ an LLM”</mark> [Page 14](zotero://open-pdf/library/items/4L4ULCUY?page=14&annotation=BMFRZPQ4) 

> [!context]-
> ==(How this article relates to other work in the field; how it ties in with key issues and findings by others, including yourself)==
> context:: 

> [!significance]-
> ==(to the field; in relation to your own work)==
> significance:: 