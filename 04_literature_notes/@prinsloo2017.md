---
category: literature_note
aliases: 
  - Fleeing from Frankenstein’s monster and meeting Kafka on the way: Algorithmic decision-making in higher education
  - prinsloo2017
tags:
  - literature_note
  - zotero
  - 
citekey: prinsloo2017
---

|       Created       |    Last Modified    |          Exists Since           |
| :-----------------: | :-----------------: | :-----------------------------: |
| `= this.file.ctime` | `= this.file.mtime` | `= date(now) - this.file.ctime` |
>[!info] Metadata
> **FirstAuthor**:: Prinsloo, Paul  
~    
> **Title**:: Fleeing from Frankenstein’s monster and meeting Kafka on the way: Algorithmic decision-making in higher education  
> **Year**:: 2017   
> **Citekey**:: prinsloo2017  
> **itemType**:: journalArticle  
> **Journal**:: *E-Learning and Digital Media*  
> **Volume**:: 14  
> **Issue**:: 3   
> **Pages**:: 138-163  
> **url**:: https://journals.sagepub.com/doi/10.1177/2042753017731355
> **DOI**:: 10.1177/2042753017731355    

> [!link]-
> zotero_link:: [Prinsloo_2017_Fleeing from Frankenstein’s monster and meeting Kafka on the way Algorithmic decision-making in hig.pdf](zotero://select/library/items/4JSA36XT)

> [!cite]-
> citekey:: prinsloo2017

> [!abstract]-
> abstract:: In the socio-technical imaginary of higher education, algorithmic decision-making offers huge potential, but we also cannot deny the risks and ethical concerns. In fleeing from Frankenstein’s monster, there is a real possibility that we will meet Kafka on our path, and not find our way out of the maze of ethical considerations in the nexus between human and nonhuman agencies.
            In this conceptual article, I map seven dimensions of student surveillance on an experimental matrix of human-algorithmic interaction to consider some of the ethical implications of algorithmic decision-making in higher education. The experimental matrix of human-algorithmic decision-making uses the four tasks of ‘sensing’, ‘processing’, ‘acting’ and ‘learning’ to open up algorithmic-human agency as comprising a number of possibilities such as (1) where only humans perform the task; (2) where the task is shared between humans and algorithms; (3) where algorithms perform the task but with humans supervising; and (4) where algorithms perform the tasks with no human oversight.
            I use this matrix to engage with seven dimensions of how higher education institutions collect, analyse and use student data namely (1) automation; (2) visibility; (3) directionality; (4) assemblage; (5) temporality; (6) sorting; and (7) structuring. The article concludes by proposing a number of pointers to be taken into consideration when implementing algorithms in a higher education context from a position of an ethics of care.

> [!keywords]-
> keywords:: 

> [!authors]-
> authors:: Paul Prinsloo

> [!related]-


```dataview
TABLE created, updated as modified, tags, type
FROM ""
WHERE related != null
AND contains(related, "prinsloo2017")
```

> [!hypothesis]-
> hypothesis:: 

> [!methodology]- 
> methodology:: 

> [!result]- Result(s) 
> results::

> [!summary]- Summary of Key Points
> summary:: 

# Notes

| <mark class="hltr-grey">Highlight Color</mark> | Meaning                       |
| ---------------------------------------------- | ----------------------------- |
| <mark class="hltr-yellow">Yellow</mark>        | Interesting Point             |
| <mark class="hltr-orange">Orange</mark>        | Important Point By Author     |
| <mark class="hltr-red">Red</mark>              | Disagree with Author          |
| <mark class="hltr-blue">Blue</mark>            | Support the Author            |
| <mark class="hltr-magenta">Magenta</mark>      | Important To Me               |
| <mark class="hltr-purple">Purple</mark>        | Literary Note To Lookup Later |
| <mark class="hltr-green">Green</mark>          | Example                       |
| <mark class="hltr-grey">Grey</mark>            | New term, - definition        |

- <mark class="hltr-orange">"Algorithms “govern” because they have the power to structure possibilities. They define which information is to be included in an analysis; they envision, plan for, and execute data transformations; they deliver results with a kind of detachment, objectivity, and certainty; they act as filters and mirrors, selecting and reflecting information that make sense within an algorithm’s computational logic and the human cultures that created that logic. (Beer, 2017a: 97–98)”</mark> [Page 6](zotero://open-pdf/library/items/4JSA36XT?page=6&annotation=3CDEYZ24) 
	- <mark class="hltr-orange">"Algorithms produce truths through making material interventions related to issues such as the choices individuals have (or don’t have), risk assessments, health classifications, etc. It is also important to note how the notion of the algorithm is deployed to ‘create or perpetuate certain truths about social orders and the like, or how certain truths are”</mark> [Page 6](zotero://open-pdf/library/items/4JSA36XT?page=6&annotation=647TGVCH) 
	- <mark class="hltr-orange">"cultivated through discussions or evocations of the algorithm’ (Beer, 2017a: 8). The ‘algorithm’s power may not just be in the code, but in that [sic] way that it becomes part of a discursive understanding of desirability and efficiency’ (Beer, 2017a: 8) and ‘a code of normalisation’ (Foucault, 2004, quoted by Beer, 2017a: 9).”</mark> [Page 7](zotero://open-pdf/library/items/4JSA36XT?page=7&annotation=2MEPF5UA) 
	- <mark class="hltr-orange">"As the profile of algorithms has grown and as their actions become the source of discussion, we might want to avoid thinking of them as good and bad algorithms and think instead about how these media forms mesh human with machine agency and what this means.”</mark> [Page 7](zotero://open-pdf/library/items/4JSA36XT?page=7&annotation=F9U5QMU8) 
	


> [!context]-
> ==(How this article relates to other work in the field; how it ties in with key issues and findings by others, including yourself)==
> context:: 

> [!significance]-
> ==(to the field; in relation to your own work)==
> significance:: 