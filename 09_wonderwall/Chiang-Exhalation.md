---
kindle-sync:
  bookId: '60209'
  title: Exhalation
  author: Ted Chiang
  highlightsCount: 10
---
# Exhalation
## Metadata
* Author: [[Ted Chiang]]

## Highlights
The researchers conclude that there’s something missing in the Origami genome, but as far as Derek’s concerned, the fault lies with them. They’re blind to a simple truth: complex minds can’t develop on their own. If they could, feral children would be like any others. And minds don’t grow the way weeds do, flourishing under indifferent attention; otherwise all children in orphanages would thrive. For a mind to even approach its full potential, it needs cultivation by other minds. That cultivation is what he’s trying to provide for Marco and Polo. — location: [1601]() ^ref-42998

---
mutism was very rare, a result of damage to the anterior cingulate region of the brain. Now it spreads like a cognitive plague. — location: [902]() ^ref-31325

---
Before people started playing with Predictors, akinetic mutism was very rare, a result of damage to the anterior cingulate region of the brain. Now it spreads like a cognitive plague. — location: [901]() ^ref-38820

---
It turns out that the disabling thought is one that we’ve all encountered: the idea that free will doesn’t exist. It just wasn’t harmful until you believed it. — location: [904]() ^ref-50322

---
An automaton can’t become discouraged, only a freethinking entity can. — location: [910]() ^ref-58050

---
Unfortunately, such reasoning is faulty; every form of behavior is compatible with determinism. One dynamic system may fall into a basin of attraction and wind up at a fixed point, while another exhibits chaotic behavior indefinitely, but both are completely deterministic. — location: [912]() ^ref-46853

---
Pretend that you have free will. It’s essential that you behave as if your decisions matter, even though you know they don’t. The reality isn’t important; what’s important is your belief, and believing the lie is the only way to avoid a waking — location: [917]() ^ref-57322

---
coma. Civilization now depends on self-deception. Perhaps it always has. — location: [918]() ^ref-53436

---
So why did I do it? Because I had no choice. — location: [921]() ^ref-10229

---
“We won’t always be restricted to running them in real time. At some point there’ll be enough digients to form a self-sufficient population, and then they won’t be dependent on human interaction. We could run a society of them at hothouse speeds without any risk of them going feral, and see what they produce.” Ana’s actually far from confident that this scenario would produce a Turing, but she’s practiced this argument enough times to sound like she believes it. — location: [2473]() ^ref-15893

---
