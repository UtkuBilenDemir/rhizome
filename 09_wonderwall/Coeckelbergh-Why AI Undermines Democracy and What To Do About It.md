---
kindle-sync:
  bookId: '3802'
  title: Why AI Undermines Democracy and What To Do About It
  author: Mark Coeckelbergh
  asin: B0CVSMD9BL
  lastAnnotatedDate: '2024-05-20'
  bookImageUrl: 'https://m.media-amazon.com/images/I/51z4ISYGQUL._SY160.jpg'
  highlightsCount: 65
---
# Why AI Undermines Democracy and What To Do About It
## Metadata
* Author: [[Coeckelbergh, Mark]]

## Highlights
“organized as processes of communication where humans inform themselves, debate, and take collectively binding decisions” (2023: 12). This requires a public sphere: a social sphere where people can freely discuss political problems and thus form a public and a public opinion. — location: [678]() ^ref-37923

---
Dewey and Habermas stressed not only participation but also communication. In Democracy and Education (1944), Dewey sees communication as a process in which participants learn to see the perspective of others and cooperate on shared problems; this enables both personal and societal growth. One could say that it leads to more community, understood as a coming together. For Habermas, “communicative action” (1984) is about the pursuit of goals based on a shared understanding. — location: [686]() ^ref-56141

---
we learn to develop ourselves and we develop ourselves as a community. — location: [692]() ^ref-49744

---
But that excluded the rest of the population; the class of citizens covered only a small part of the Athenian population. Arendt’s analysis of politics in The Human Condition (1998 [1958]), which celebrates political action as opposed to work and labor, is inspired by this ancient, hierarchical model of activities, itself based on a hierarchical model of society: the ancient male citizens talk politics, while the work and household is done by others who were excluded from that form of “democracy”: women, slaves, craftsmen. — location: [706]() ^ref-50798

---
Is direct democracy possible when most of us are caught up in stressful jobs, exhausting family activities, and a demanding socioeconomic system and technological environment that leaves little time and energy for political activities? Moreover, today expert knowledge seems to be required to understand what goes on in complex knowledge societies, with science and technology playing a key role. This creates a challenge for democracy, at least in its direct form. Can and should all of us have this knowledge? The traditional republican answer is: yes. — location: [712]() ^ref-38625

---
If systems go too much to the side of knowledge and expertise, they face the objection that truth can be tyrannical: it can lead to technocracy, or at least technocracy in its authoritarian form. At first sight, it sounds good to say that government should be based on the truth. But can we be certain that a particular view is the truth? Who decides this? Perhaps there is no single truth. — location: [725]() ^ref-50474

---
on the other hand, political systems go too much to the side of democracy (at least, if simply understood as majority rule, what Arendt calls “counting noses”), the majority can become tyrannical as well, and ignorance can reign. — location: [731]() ^ref-7635

---
The actual situation is that everywhere the forces of democracy and authoritarianism are subject to continuous interaction, negotiation, blending, and change. There are democratic and anti-democratic forces. There are blends and compromises. There are changes. Today, the direction of change is often towards authoritarianism, even in the West. Nunes Da Costa (2022) uses the term “democratic despotisms” to refer to tendencies to despotism in today’s democratic contexts. — location: [752]() ^ref-9873

---
when discussion in the public space is plagued by undemocratic tendencies, including the intended creation of polarization and attempts to silence others.4 (I will say more about these effects of AI in the next chapters.) — location: [768]() ^ref-25732

---
Rousseau also argued that radical economic inequality is bad for democracy since it leads to the wealthy making laws that are in their interests, it turns the poor against each other so that they are divided and do not exercise their power against the wealthy, and makes the rich addicted to the pleasure of dominating the poor without caring about justice. More economic equality prevents this and thus supports democracy. — location: [885]() ^ref-20271

---
it can be used to condemn “the social abandonment of the weakest members of society” (2019: 6).2 In other words, a democracy that does not in some way or other care about its weakest members does not deserve the name of democracy. — location: [892]() ^ref-48157

---
the rule of law, rather than the rule of men, is meant to secure liberty against domination (Sellers 2015). — location: [910]() ^ref-36030

---
Zeng (2020) has argued that it is not AI itself that is the problem but rather AI in combination with, for example, ideological components. But there is no such thing as “AI itself” anyway. AI is always linked with other human systems. Here my claim is that AI – as used by humans and integrated with other systems – does not only erode democracies but also strengthens already existing forms of authoritarianism and totalitarianism, thus violating the principles of freedom and fraternity, and rendering application of republican and Enlightenment democratic ideals, such as tolerance and the public sphere, impossible. — location: [1095]() ^ref-12489

---
This also has a knowledge dimension: totalitarianism impacts knowledge in society. — location: [1144]() ^ref-17198

Foucault frokm BA

---
Now this problem can also be linked to AI and data science. Used in a bureaucratic way that alienates actual people and discourages engagement with its consequences, data science can have bad effects on individuals and society – even potentially supporting mass murder and systematic genocide – without necessarily involving evil data scientists or evil intentions on the part of these scientists. — location: [1159]() ^ref-36980

---
In The Origins of Totalitarianism (2017 [1951]), Arendt writes that totalitarian governments create a “fictitious world through consistent lying” (2017 [1951]: 499). They disdain truth and reality, shielding themselves and their followers “from the impact of factuality” (2017 [1951]: 549). — location: [1178]() ^ref-64437

---
But social disconnection can also have political consequences: as Putnam has argued in his book Bowling Alone (2020), about the collapse of community in the United States, a decline in the social fabric undermines active civic engagement required in a strong democracy. — location: [1187]() ^ref-21596

---
Earlier, Durkheim (1997 [1897]) had stressed the importance of social connection and shown that its absence in modern society can lead to suicide. But social disconnection can also have political consequences: as Putnam has argued in his book Bowling Alone (2020), about the collapse of community in the United States, a decline in the social fabric undermines active civic engagement required in a strong democracy. — location: [1185]() ^ref-8817

---
Moreover, according to Arendt, political judgment requires common sense (Arendt 1968), being interested in the common good, and being able to use one’s imagination to visit each other’s standpoints. If we are just defending our own opinion but are not interested in understanding others’ points of view, we cannot reach a common understanding. If this is no longer possible, then the basis for democracy is destroyed: not only are there no longer fraternity and tolerance, but also no common understanding and no common world. If and insofar as AI, in combination with digital social media, helps to create a political environment that leads to isolation, mistrust, and lack of interest in each other’s point of view, it destroys the conditions for the emergence of common sense and thus enables anti-democratic, potentially totalitarian tendencies. True communication, in the republican and Enlightenment sense of the word, is then no longer possible. (I will say more about communication and democracy in chapter 8.) — location: [1191]() ^ref-48375

---
Knowledge is power: if others “know almost everything about us” through AI, then they have the power (Véliz 2020: 86). Citizens thus lose agency: epistemic agency and political agency. Having no access to knowledge, they do not make decisions about their data and about the use of AI. Others decide – governments and big tech. — location: [1212]() ^ref-44881

Research Veliz

---
Examples of what Zarkadakis (2020) calls “automating the government” are the social welfare cases I mentioned in the first chapter, but also how governments across the world dealt with the Covid-19 pandemic. Using AI, big data, and (medical) expert knowledge, governments created an asymmetrical knowledge situation for the governance of the pandemic, which translated into a widening power gap between governments and citizens, moving societies in the direction of technocracies, perhaps even towards digital authoritarianism. — location: [1219]() ^ref-16415

Researc Zarkadakis

---
AI politics thus starts with the creation of the datasets, which is a moment of exclusion. As Bartoletti has put it, we are entered into datasets by an “unseen force” (2020: 38). This also means that others make decisions about who becomes part of the dataset and who is left out. This is a political decision. In a democracy, decisions about who is “in” and who is “out” should be made democratically, that is, by the citizens or their representatives. Instead, others, in particular governments and (big) tech, make these decisions for us based on the knowledge they have. These are technocratic, not democratic, decisions. — location: [1229]() ^ref-49265

---
if power is centralized and based on knowledge that is not necessarily shared with all citizens. Arguably, this was the case in twentieth-century authoritarian systems that were called “communist” or “socialist.” In post-communist countries such as China and Russia, we see a continuation of that political tradition, or at least its knowledge/power asymmetries. — location: [1237]() ^ref-65312

---
They can even be used to convince us that something real is false (Meikle 2022). — location: [1261]() ^ref-9427

Research Meikle

---
Furthermore, as suggested previously, epistemic bubbles are a problem for fraternity and are divisive for society. But they also create the wrong kind of knowledge basis for democracy since the diversity of views is reduced and relevant knowledge is excluded. For democratic voting and public deliberation, it is vital that I am exposed to a diverse pool of views and that I have sufficient political knowledge. An epistemic bubble or echo chamber decreases diversity of views, fragments the public sphere, and prevents the adequate formation of my political beliefs and views – or at least renders the revision of such views difficult. Imagine, for instance, that some people have racist views but are willing to discuss and potentially revise those views in the light of other views and scientific evidence. This requires that they are sufficiently exposed to other views and to science. But this is impossible if they remain in a racist bubble. Whether or not they are kept there on purpose (whether or not the effect is intentional), the result is the persistence of a narrow epistemic basis for the exercise of their democratic agency. In other words, they have insufficient epistemic agency for exercising their democratic citizenship. — location: [1272]() ^ref-44644

Particularly important for me

---
that your social welfare institution suddenly stops your welfare benefit by saying that the AI decided to stop it. Who is responsible for this decision, and how can we avoid nobody being held accountable? — location: [1308]() ^ref-28857

---
The Enlightenment assumption was that we are autonomous subjects who reason with one another about politics in the public arena. But if AI knows me better than I know myself (or at least that is the claim of the tech industry) because it tracks my behavior and categorizes and influences my beliefs without my knowledge, then this kind of political practice seems undermined. — location: [1332]() ^ref-49376

---
It is therefore mandatory to create epistemic environments that produce political subjects with a degree of epistemic agency and autonomy that is sufficient and adequate for the mentioned ideals of democracy. — location: [1350]() ^ref-6747

---
We need to make democracy stronger. Democracy is a great idea, but it still needs to be fully realized. In particular, if we move away from the minimal, thin conception of democracy as a voting procedure and embrace a richer ideal – one inspired by republican, Enlightenment, and deliberative approaches – that includes participation, public deliberation, and social communication, then the potentially negative impact of AI and other technologies will have more chance to be mitigated. While AI is political through and through (Coeckelbergh 2022a), in itself its use is unlikely to sink democracy, unless that democracy is already seriously in trouble. If we strengthen and further develop our democratic institutions, we diminish the risks discussed so far. — location: [1376]() ^ref-44706

---
One important instrument for preserving democracy is the law. As Susskind (2022) has argued in defense of what he calls “digital republicanism,” the law must preserve democratic institutions and curb “the unaccountable power of those who design and control digital technology” and their market individualism, which wrongly believes that everything can be left to individuals and their companies pursuing their own interests (Susskind 2022: 11). — location: [1382]() ^ref-61584

---
And in liberal democracies we have parliaments, which are supposed to represent the people (rather than big tech) and who can make laws to limit the power of the tech sector. I will soon say more about AI regulation. — location: [1388]() ^ref-62578

We need something new, institutional change and new institutions. And the changemight idicates a complete paradigm shift

---
But beyond conservation of what we already have, we also need to build something new. We need institutional change. We need to transform our political institutions into a more participative and communicative direction. — location: [1390]() ^ref-26294

---
Landemore (2020) has proposed what she calls an “open mini-public”: a jury of randomly selected citizens who deliberate and make the laws. — location: [1392]() ^ref-61642

Find more examples

---
At the same time, ordinary citizens are involved in the decision making, rather than political elites or tech billionaires. AI could also help here (see pp. 87–91). — location: [1394]() ^ref-61993

Anlyse those

---
And how resistant is this model against populism and extremism? What other interventions might be (more?) productive for a knowledge-informed democracy? — location: [1398]() ^ref-44833

Do constrains cause a manipulated ai, and open the question of legitimacy?

---
With regard to the Constitution, we need to transform our constitutional order in a way that gives sufficient and effective power to democratically elected bodies as opposed to judicial powers and big tech, while ensuring that there is enough input from expertise. — location: [1400]() ^ref-29401

---
Another important democratic institution that should be mentioned in this context is quality journalism. Journalism, — location: [1409]() ^ref-36037

---
Journalists already had to fact-check and facilitate the spread of truthful information before AI took centre stage, but in the current context of misinformation promoted by the use of AI, this role becomes more important (Bimber and de Zúñiga 2020). Beyond those who play this critical role in classical media such as newspapers and TV, we need more “editors” and “moderators” of discussions in the public sphere as mediated by digital social media: we need people who can help citizens with their political-epistemic challenges. — location: [1412]() ^ref-63845

---
Here AI is not necessarily a threat but can assist, for example by automatically presenting articles that disrupt the homogenous newsfeed of a reader (Lin and Lewis 2022) and by playing the role of gatekeepers (Duberry 2022) in order to protect democracy against anti-democratic forms of populism and the rise of various forms of authoritarianism. — location: [1417]() ^ref-35308

Can list a couple of negative possibilities as well here

---
used to mitigate the enabling role that digital media play in giving such people a voice and contributing to their success. — location: [1421]() ^ref-9096

Do we have a process to gurantee that? Thats profiling.

---
keeping in mind, of course, that freedom of expression is also an important value in a democracy. — location: [1422]() ^ref-54125

---
the view that technology shapes society according to its internal logic and thus determines our future, with only a minimal role for humans – often goes hand in hand with political conservatism and laissez-faire. As Brevini (2022) notes, faith in technology is often used as “a powerful apology for the status quo and for the current structure of capitalism, without leaving any real space for critique” (2022: 21). Moving instead beyond determinism and techno-solutionism, which wrongly believes that there is a technological solution for all our social and political problems, we can find such a space for critique and indeed for action. If there is currently a power imbalance, then we as citizens can critique, resist, and take back the power. — location: [1433]() ^ref-3001

---
This is not only important from a legal perspective, in order to ensure legal accountability (see, for example, Katyal 2022), but also from an ethical and political perspective. As I write, there are several national proposals for regulation, such as the White House’s Blueprint for an AI Bill of Rights3 from the Biden administration. And following the European Commission’s proposal for a European Union regulatory framework on AI,4 which is partly based on the recommendations by the Commission’s High-Level Expert Group on AI, the AI Act5 has been approved in the European Parliament. — location: [1447]() ^ref-28623

---
For example, the EU says its regulation is based on European values and fundamental rights, and the UNESCO Recommendation lists a number of values and principles, such as respect for human rights and dignity, fundamental freedoms, environmental and ecosystem flourishing, diversity and inclusiveness, no harm, fairness and non-discrimination, transparency, and accountability.7 While discussions about AI policy have seen different views on which ethical principles should be used (for example, whether bioethics principles should be the basis, as Floridi and Cowls [2019] have proposed) and while high-level principles alone are insufficient to guarantee ethical AI (see, for example, Mittelstadt 2019), everyone agrees that ethics should be the basis of AI regulation. — location: [1458]() ^ref-46130

---
Note, however, that ethics is sometimes used to justify a politics of laissez-faire and self-regulation. Ethics then becomes ethics washing. But avoidance of AI legislation is undemocratic — location: [1465]() ^ref-9228

---
If big tech does not avoid regulation, it does at least try to deeply influence it. — location: [1469]() ^ref-64535

---
But for the sake of democracy and the common good, that influence and involvement needs to be limited. — location: [1471]() ^ref-34109

---
The problem, therefore, is not just what and how much regulation we need; as the previous section proposed, we also need to critically reflect on our institutions, which apparently are hardly resilient in the face of the current developments. — location: [1474]() ^ref-52197

---
some infrastructures, and the roles of gatekeeper or moderator are too important to leave to private initiative. One option, for example, is to turn some of the big tech companies into public utilities, as Risse (2023: 71) has proposed. — location: [1481]() ^ref-30292

---
Should the technology (and its profits and benefits) be democratized, in the sense of shared or publicly owned? One reason why currently regulation does not happen or is kept minimal is the persistence of the idea that technology development should be mainly, if not exclusively, a matter of private initiative, private ownership, and private capital. — location: [1483]() ^ref-50241

---
As Marxian thinkers such as Dyer-Witheford, Kjosen, and Steinhoff (2019) and Fuchs — location: [1487]() ^ref-2337

---
For example, Fuchs (2023) defends a socialist version of democracy, which he defines as one which “advances the common economic, political and cultural good of all humans” (2023: 13), and which would be supported by digital technologies. His socialist version of what he calls “digital democracy” (2023: 12) implies, among other things, that more support is given to independent public media (2023: 297); this would help journalists to play their democracy-supporting role mentioned earlier. — location: [1487]() ^ref-16713

---
The idea is that digital technologies and resources such as data should be communally owned and shared. Consider, for example, Wikipedia or open-source software, which can be freely used and to which everyone can contribute. — location: [1495]() ^ref-53642

---
A different idea is digital socialism (Muldoorn 2022), which would entail common ownership of data, participation of workers and communities, and democratic control over investment – thus achieving a more radical redistribution of power that goes beyond an individualist approach. — location: [1501]() ^ref-64648

---
AI more “common.” Similarly, we should ask what democracy and the use of AI means in the light of ecological and climate challenges, and — location: [1506]() ^ref-61806

---
if capitalism and free-market thinking can sufficiently deal with these challenges. Critical theory (broadly conceived), combined with environmental theory, can help to conceive of alternative systems. But even from a market perspective, one could argue for breaking up global monopolies and oligopolies in order to preserve competition and maintain a level playing field. — location: [1507]() ^ref-65477

---
regulatory efforts only make sense if there is some harmonization and coordination at supranational and global level. — location: [1512]() ^ref-12391

---
As with many other urgent global matters, such as climate change, pandemic, and war, when it comes to global governance of AI we still find ourselves in a kind of Hobbesian state of nature: there is no global governance authority, and nationalism threatens efforts to respond to the urgent need to better coordinate. That being said, global governance has its own challenges, such as negotiating different political cultures and traditions, and of course ensuring and maintaining the democratic character of governance at such a level. — location: [1522]() ^ref-60745

---
“value sensitive design” (Friedman and Hendry 2019; Van Den Hoven 2013), which proposes methods to take into account human values in the design of new technologies, and the concept of “responsible research and innovation” (Owen, Macnaghten, and Stilgoe 2012; Von Schomberg 2013), which also aims to take into account ethics by, among other things, involving stakeholders in research and innovation processes. Similarly, and entirely compatible with the spirit of these methods and visions, I propose that for the politically responsible development of AI, political values and concerns should be taken into account, and that politically relevant stakeholders be involved in its development. — location: [1544]() ^ref-24390

---
In technology ethics, it has already been argued that technology is never neutral and has a moral dimension (Verbeek [2011] and earlier Latour [2002]), and that therefore we should better open and shape the process of its moral-technological development. Similarly, and in addition, one should also acknowledge, — location: [1556]() ^ref-58037

---
real change can only happen if we also change the technologies, not just the institutions. If power also comes from technology and not just from what people do in parliaments — location: [1563]() ^ref-14209

---
then real change can only happen if we also change the technologies, not just the institutions. — location: [1563]() ^ref-4640

---
In particular, I propose democratic AI development (DAD) and democracy by design11 aimed at supporting the growth of what we could call a technodemocracy: not a technocracy but a democracy that continuously and systematically reflects on, and transforms, itself and its technologies based on the awareness that technologies such as AI are always political, and that therefore — location: [1570]() ^ref-56566

---
aims at developing democratic technologies. We need software, innovation processes, and regulations that connect the development of technology in more direct and more effective ways with discussions about politics and democracy and, preferably, with democratic decision-making processes, democratic procedures, and democratic institutions. — location: [1574]() ^ref-65118

---
Note, however, that my argument for rendering AI development more “political” does not imply the claim that technology development should be politicized in the bad sense of the word: one that implies the total loss of independence on the part of the companies and one that simply replaces one centralist form of power with another. — location: [1583]() ^ref-20242

---
if not entangle, research and innovation processes with political institutions. Given that today much AI development takes place outside democratic control, we need to properly and rigorously embed that development in democracy. Instead of ad hoc deliberations about new technologies such as AI and other specific technologies (as is now the case) and instead of relying on the goodwill of big tech leaders to include stakeholder views, we need to create more permanent, institutional solutions that can mediate between politics and technology development, and between experts and citizens. For example, a new, permanent institution could enable citizens as users of AI and social media platforms to talk to experts who develop(ed) these platforms and the related AI, directly or via mediators. The results of such mediations and discussions should then regularly flow back to the development process. — location: [1596]() ^ref-38533

Co-creation

---
Moreover, we should not take the current epistemic and political state of citizens for granted. It is true that there is a lot of ignorance, and sometimes even anti-intellectualism, as in the United States, for example.12 Plato’s complaint about the masse <You have reached the clipping limit for this item> — location: [1609]() ^ref-64320

---
<You have reached the clipping limit for this item> — location: [1744]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [1760]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [1791]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [1838]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [1863]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [1906]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [1952]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [1960]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [1981]() ^ref-28093

Deleuze Dewey connection

---
<You have reached the clipping limit for this item> — location: [2000]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [2040]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [2118]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [2145]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [2160]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [2187]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [2197]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [2199]() ^ref-28093

---
<You have reached the clipping limit for this item> — location: [2205]() ^ref-28093

---

Moreover, we should not take the current epistemic and political state of citizens for granted. It is true that there is a lot of ignorance, and sometimes even anti-intellectualism, as in the United States, for example.12 Plato’s complaint about the masses is far from irrelevant. But again, this situation should not be just taken as given or natural, and the problem is not totally hopeless or unavoidable. A classic republican and Enlightenment recipe for citizen empowerment is education. Democracy, especially in its richer formulations, may well end with rule by the people but it starts with education. — location: [1609](kindle://book?action=open&asin=B0CVSMD9BL&location=1609) ^ref-25748

---
